{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD（no）+ crossEntrpy + bs256 + tanh + lr0.01\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 线性层\n",
    "class LinearLayer:\n",
    "    def __init__(self, n_in, n_out, batch_size, activation=None, lr=0.001):\n",
    "        # 初始化模型参数\n",
    "        self.W = np.random.normal(scale=0.01, size=(n_in, n_out))\n",
    "        self.b = np.zeros((batch_size, n_out))\n",
    "        self.activation = activation\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "    # 前向传播\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        output = np.dot(x, self.W) + self.b\n",
    "        if self.activation == 'relu':\n",
    "            output = np.maximum(0, output)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            output = 1 / (1 + np.exp(-output))\n",
    "        elif self.activation == 'tanh':\n",
    "            output = np.tanh(output)\n",
    "        self.activated_output = output\n",
    "        return output\n",
    "    # 反向传播（SGD）\n",
    "    def backward(self, dout):\n",
    "        if self.activation == 'relu':\n",
    "            dout = dout * (self.activated_output > 0) # relu的导数\n",
    "        elif self.activation == 'sigmoid':\n",
    "            dout = self.activated_output * (1 - self.activated_output) * dout # sigmoid的导数\n",
    "        elif self.activation == 'tanh':\n",
    "            dout = (1 - self.activated_output ** 2) * dout # tanh的导数\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = dout\n",
    "        # 更新参数\n",
    "        self.W = self.W - self.dW * self.lr / self.batch_size\n",
    "        self.b = self.b - self.db * self.lr / self.batch_size\n",
    "        return dx\n",
    "\n",
    "# SoftMax层\n",
    "class SoftMax:\n",
    "    def __init__(self):\n",
    "        self.y_hat = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_exp = np.exp(x - np.max(x, axis=1, keepdims=True))  # 防止溢出\n",
    "        partition = np.sum(x_exp, axis=1, keepdims=True)\n",
    "        self.y_hat = x_exp / partition\n",
    "        return self.y_hat\n",
    "\n",
    "    def backward(self, y):\n",
    "        dout = self.y_hat - y\n",
    "        return dout\n",
    "\n",
    "\n",
    "# 多层感知机\n",
    "class MLP:\n",
    "    def __init__(self, input_size, batch_size, num_classes, \n",
    "                 lr=0.001, hidden_layer_sizes=(256,), \n",
    "                 activation='relu'):\n",
    "        self.input_layer = LinearLayer(input_size, \n",
    "                                       hidden_layer_sizes[0], batch_size, \n",
    "                                       activation, lr=lr)\n",
    "        self.classifier = LinearLayer(hidden_layer_sizes[-1], \n",
    "                                      num_classes, batch_size,\n",
    "                                      None, lr=lr)\n",
    "        self.softmax = SoftMax()\n",
    "\n",
    "        self.layers = [self.input_layer]\n",
    "        for i in range(len(hidden_layer_sizes) - 1):\n",
    "            self.layers.append(LinearLayer(hidden_layer_sizes[i], \n",
    "                                           hidden_layer_sizes[i + 1],\n",
    "                                           batch_size, activation, \n",
    "                                           lr=lr))\n",
    "        self.layers.append(self.classifier)\n",
    "        self.layers.append(self.softmax)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, y):\n",
    "        for layer in reversed(self.layers):\n",
    "            y = layer.backward(y)\n",
    "\n",
    "# 加载CIFAR-10数据\n",
    "def load_cifar10_data(data_dir, valid_ratio=0.2):\n",
    "    def load_batch(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            batch = pickle.load(fo, encoding='bytes')\n",
    "        data = batch[b'data']\n",
    "        labels = np.array(batch[b'labels'])\n",
    "        return data, labels\n",
    "\n",
    "    X_train, y_train = [], []\n",
    "    for i in range(1, 6):\n",
    "        data, labels = load_batch(os.path.join(data_dir, f'data_batch_{i}'))\n",
    "        X_train.append(data)\n",
    "        y_train.append(labels)\n",
    "\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    X_test, y_test = load_batch(os.path.join(data_dir, 'test_batch'))\n",
    "\n",
    "    X_train = X_train.reshape(-1, 3, 32, 32).astype('float32') / 255.0\n",
    "    X_test = X_test.reshape(-1, 3, 32, 32).astype('float32') / 255.0\n",
    "\n",
    "    y_train = np.eye(10)[y_train]\n",
    "    y_test = np.eye(10)[y_test]\n",
    "\n",
    "    # 将训练数据划分为训练集和验证集\n",
    "    valid_size = int(X_train.shape[0] * valid_ratio)\n",
    "    indices = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X_train, X_valid = X_train[indices[:-valid_size]], X_train[indices[-valid_size:]]\n",
    "    y_train, y_valid = y_train[indices[:-valid_size]], y_train[indices[-valid_size:]]\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test\n",
    "\n",
    "# 定义数据加载器\n",
    "def dataloader(X, y, batch_size):\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(X) - batch_size + 1, batch_size):\n",
    "        excerpt = indices[start_idx:start_idx + batch_size]\n",
    "        yield X[excerpt], y[excerpt]\n",
    "\n",
    "# 加载数据集\n",
    "data_dir = 'Datasets/cifar-10-batches-py'\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_cifar10_data(data_dir)\n",
    "\n",
    "# 展平输入数据\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# 训练超参数\n",
    "num_epochs = 1000\n",
    "batch_size = 256\n",
    "\n",
    "# 初始化模型\n",
    "model = MLP(input_size=3072, batch_size=batch_size, num_classes=10, lr=0.01, hidden_layer_sizes=(256,), activation='tanh')\n",
    "\n",
    "# 初始化列表以存储每个epoch的损失和准确率\n",
    "train_losses, valid_losses = [], []\n",
    "train_accuracies, valid_accuracies = [], []\n",
    "\n",
    "# 提前停止类\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0):\n",
    "        self.patience = patience  # 容忍的epoch数\n",
    "        self.min_delta = min_delta  # 最小变化量\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, valid_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = valid_loss\n",
    "        elif valid_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = valid_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# 设置提前停止\n",
    "early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练阶段\n",
    "    train_loss, train_acc = 0, 0\n",
    "    with tqdm(dataloader(X_train, y_train, batch_size), unit='batch') as tepoch:\n",
    "        for data, label in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch + 1} train\")\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model.forward(data)\n",
    "            loss = np.mean(-np.sum(label * np.log(outputs + 1e-8), axis=1))  # 交叉熵损失\n",
    "            train_loss += loss\n",
    "            train_acc += (outputs.argmax(1) == label.argmax(1)).sum() / len(X_train)\n",
    "\n",
    "            # 反向传播\n",
    "            model.backward(label)\n",
    "\n",
    "            # 更新进度条中的准确率\n",
    "            tepoch.set_postfix(train_acc=train_acc)\n",
    "\n",
    "    train_losses.append(train_loss / len(X_train))\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # 验证阶段\n",
    "    valid_loss, valid_acc = 0, 0\n",
    "    with tqdm(dataloader(X_valid, y_valid, batch_size), unit='batch') as vepoch:\n",
    "        for data, label in vepoch:\n",
    "            vepoch.set_description(f\"Epoch {epoch + 1} valid\")\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model.forward(data)\n",
    "            loss = np.mean(-np.sum(label * np.log(outputs + 1e-8), axis=1))\n",
    "            valid_loss += loss\n",
    "            valid_acc += (outputs.argmax(1) == label.argmax(1)).sum() / len(X_valid)\n",
    "\n",
    "            vepoch.set_postfix(valid_acc=valid_acc)\n",
    "\n",
    "    valid_losses.append(valid_loss / len(X_valid))\n",
    "    valid_accuracies.append(valid_acc)\n",
    "\n",
    "    # 检查是否应该提前停止\n",
    "    early_stopping(valid_loss / len(X_valid))\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"提前停止在第 {epoch + 1} 轮\")\n",
    "        break\n",
    "\n",
    "\n",
    "# 测试阶段\n",
    "def test_model(model, X_test, y_test):\n",
    "    acc = 0\n",
    "    with tqdm(range(0, len(X_test), batch_size), unit='batch') as tepoch:\n",
    "        for i in tepoch:\n",
    "            tepoch.set_description(\"Testing\")\n",
    "            data = X_test[i:i+batch_size]\n",
    "            label = np.argmax(y_test[i:i+batch_size], axis=1)\n",
    "            if data.shape[0] < batch_size:\n",
    "                break\n",
    "            outputs = model.forward(data)\n",
    "            acc += (outputs.argmax(1) == label).sum() / X_test.shape[0]\n",
    "        tepoch.set_postfix(test_acc=acc)\n",
    "    print(f'测试精度: {acc * 100:.2f}%')\n",
    "\n",
    "# 调用测试函数\n",
    "test_model(model, X_test, y_test)\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs + 1), valid_losses, label='Valid Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss_plt')\n",
    "plt.legend()\n",
    "\n",
    "# 绘制准确率曲线\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), valid_accuracies, label='Valid Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy_plt')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGL_cpu_k",
   "language": "python",
   "name": "dgl_cpu_k"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
